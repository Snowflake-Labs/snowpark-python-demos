{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the imports we will need\n",
    "import json\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Snowflake session / connection\n",
    "\n",
    "with open('creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['user']\n",
    "    PASSWORD = data['password']\n",
    "    ROLE = data['role']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    SF_WH = data['warehouse']\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "   \"account\": SF_ACCOUNT,\n",
    "   \"user\": USERNAME,\n",
    "   \"password\": PASSWORD,\n",
    "   \"role\": ROLE\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment: \n",
    "\n",
    "# create database & make it active in this session (\"use\" it)\n",
    "session.sql('CREATE OR REPLACE DATABASE HOL_DB').collect()\n",
    "session.use_database('HOL_DB')\n",
    "\n",
    "# create a stage pointing at the S3 bucket with the sample data\n",
    "session.sql(''' CREATE OR REPLACE STAGE FROSTBYTE_RAW_STAGE\n",
    "                URL = 's3://sfquickstarts/data-engineering-with-snowpark-python/'\n",
    "                ;''').collect()\n",
    "\n",
    "# create a medium size warehouse\n",
    "session.sql('CREATE OR REPLACE WAREHOUSE HOL_WH WAREHOUSE_SIZE = MEDIUM, AUTO_SUSPEND = 300, AUTO_RESUME= TRUE;').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of tables & targets for loading\n",
    "POS_TABLES = ['country', 'franchise', 'location', 'menu', 'truck', 'order_header', 'order_detail']\n",
    "CUSTOMER_TABLES = ['customer_loyalty']\n",
    "TABLE_DICT = {\n",
    "    \"pos\": {\"schema\": \"PUBLIC\", \"tables\": POS_TABLES},\n",
    "    \"customer\": {\"schema\": \"PUBLIC\", \"tables\": CUSTOMER_TABLES}\n",
    "}\n",
    "\n",
    "# SNOWFLAKE ADVANTAGE: Schema detection\n",
    "# SNOWFLAKE ADVANTAGE: Data ingestion with COPY\n",
    "# SNOWFLAKE ADVANTAGE: Snowflake Tables (not file-based)\n",
    "\n",
    "def load_raw_table(session, tname=None, s3dir=None, year=None, schema=None):\n",
    "    session.use_schema(schema)\n",
    "    if year is None:\n",
    "        location = \"@frostbyte_raw_stage/{}/{}\".format(s3dir, tname)\n",
    "    else:\n",
    "        print('\\tLoading year {}'.format(year)) \n",
    "        location = \"@frostbyte_raw_stage/{}/{}/year={}\".format(s3dir, tname, year)\n",
    "    \n",
    "    # we can infer schema using the parquet read option\n",
    "    df = session.read.option(\"compression\", \"snappy\") \\\n",
    "                            .parquet(location)\n",
    "    df.copy_into_table(\"{}\".format(tname))\n",
    "\n",
    "# SNOWFLAKE ADVANTAGE: Warehouse elasticity (dynamic scaling)\n",
    "\n",
    "def load_all_raw_tables(session):\n",
    "    _ = session.sql(\"ALTER WAREHOUSE HOL_WH SET WAREHOUSE_SIZE = X2LARGE WAIT_FOR_COMPLETION = TRUE\").collect()\n",
    "\n",
    "    for s3dir, data in TABLE_DICT.items():\n",
    "        tnames = data['tables']\n",
    "        schema = data['schema']\n",
    "        for tname in tnames:\n",
    "            print(\"Loading {}\".format(tname))\n",
    "            # Only load 1 year of data for the order tables at this point\n",
    "            # We will load the 2022 data later in the lab\n",
    "            if tname in ['order_header', 'order_detail']:\n",
    "                for year in ['2021']:\n",
    "                    load_raw_table(session, tname=tname, s3dir=s3dir, year=year, schema=schema)\n",
    "            else:\n",
    "                load_raw_table(session, tname=tname, s3dir=s3dir, schema=schema)\n",
    "\n",
    "    _ = session.sql(\"ALTER WAREHOUSE HOL_WH SET WAREHOUSE_SIZE = MEDIUM\").collect()\n",
    "\n",
    "def validate_raw_tables(session):\n",
    "    # check column names from the inferred schema\n",
    "    for tname in POS_TABLES:\n",
    "        print('{}: \\n\\t{}\\n'.format(tname, session.table('PUBLIC.{}'.format(tname)).columns))\n",
    "\n",
    "    for tname in CUSTOMER_TABLES:\n",
    "        print('{}: \\n\\t{}\\n'.format(tname, session.table('PUBLIC.{}'.format(tname)).columns))\n",
    "\n",
    "load_all_raw_tables(session)\n",
    "validate_raw_tables(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Point-of-Sale view\n",
    "# select specific columns from ORDER_HEADER & add a date based on the timestamp\n",
    "order_header = session.table(\"ORDER_HEADER\"\n",
    "                     ).select(F.col(\"ORDER_ID\"), \\\n",
    "                                F.col(\"TRUCK_ID\"), \\\n",
    "                                F.col(\"ORDER_TS\"), \\\n",
    "                                F.to_date(F.col(\"ORDER_TS\")).alias(\"ORDER_TS_DATE\"), \\\n",
    "                                F.col(\"ORDER_AMOUNT\"), \\\n",
    "                                F.col(\"ORDER_TAX_AMOUNT\"), \\\n",
    "                                F.col(\"ORDER_DISCOUNT_AMOUNT\"), \\\n",
    "                                F.col(\"LOCATION_ID\"), \\\n",
    "                                F.col(\"ORDER_TOTAL\"))\n",
    "\n",
    "# select specific columns from the FRANCHISE table and rename the first/last name columns\n",
    "franchise = session.table(\"FRANCHISE\"\n",
    "                  ).select(F.col(\"FRANCHISE_ID\"), \\\n",
    "                            F.col(\"FIRST_NAME\").alias(\"FRANCHISEE_FIRST_NAME\"), \\\n",
    "                            F.col(\"LAST_NAME\").alias(\"FRANCHISEE_LAST_NAME\"))\n",
    "\n",
    "# just pull the entire table for the rest of these\n",
    "order_detail = session.table(\"ORDER_DETAIL\")\n",
    "truck = session.table(\"TRUCK\")\n",
    "menu = session.table(\"MENU\")\n",
    "location = session.table(\"LOCATION\")\n",
    "\n",
    "# join franchise to truck\n",
    "t_with_f = truck.join(franchise, truck['FRANCHISE_ID'] == franchise['FRANCHISE_ID'], rsuffix='_f')\n",
    "\n",
    "# add in order header and location\n",
    "oh_w_t_and_l = order_header.join(t_with_f, order_header['TRUCK_ID'] == t_with_f['TRUCK_ID'], rsuffix='_t') \\\n",
    "                           .join(location, order_header['LOCATION_ID'] == location['LOCATION_ID'], rsuffix='_l')\n",
    "\n",
    "# add in order detail, and menu\n",
    "final_df = order_detail.join(oh_w_t_and_l, order_detail['ORDER_ID'] == oh_w_t_and_l['ORDER_ID'], rsuffix='_oh') \\\n",
    "                       .join(menu, order_detail['MENU_ITEM_ID'] == menu['MENU_ITEM_ID'], rsuffix='_m')\n",
    "\n",
    "# itemize final column list\n",
    "final_df = final_df.select(F.col(\"ORDER_ID\"), \n",
    "                            F.col(\"TRUCK_ID\"), \n",
    "                            F.col(\"ORDER_TS\"), \n",
    "                            F.col('ORDER_TS_DATE'), \n",
    "                            F.col(\"ORDER_DETAIL_ID\"), \n",
    "                            F.col(\"LINE_NUMBER\"), \n",
    "                            F.col(\"TRUCK_BRAND_NAME\"), \n",
    "                            F.col(\"MENU_TYPE\"), \n",
    "                            F.col(\"PRIMARY_CITY\"), \n",
    "                            F.col(\"REGION\"), \n",
    "                            F.col(\"COUNTRY\"), \n",
    "                            F.col(\"FRANCHISE_FLAG\"), \n",
    "                            F.col(\"FRANCHISE_ID\"), \n",
    "                            F.col(\"FRANCHISEE_FIRST_NAME\"), \n",
    "                            F.col(\"FRANCHISEE_LAST_NAME\"), \n",
    "                            F.col(\"LOCATION_ID\"), \n",
    "                            F.col(\"MENU_ITEM_ID\"), \n",
    "                            F.col(\"MENU_ITEM_NAME\"), \n",
    "                            F.col(\"QUANTITY\"), \n",
    "                            F.col(\"UNIT_PRICE\"), \n",
    "                            F.col(\"PRICE\"), \n",
    "                            F.col(\"ORDER_AMOUNT\"), \n",
    "                            F.col(\"ORDER_TAX_AMOUNT\"), \n",
    "                            F.col(\"ORDER_DISCOUNT_AMOUNT\"), \n",
    "                            F.col(\"ORDER_TOTAL\"))\n",
    "\n",
    "# create a view based on the above\n",
    "final_df.create_or_replace_view('POS_FLATTENED_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a quick look at the result\n",
    "tv = session.table('POS_FLATTENED_V')\n",
    "tv.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get (and peak at) historical weather data for Spain\n",
    "weather = session.table('FROSTBYTE_WEATHERSOURCE.ONPOINT_ID.HISTORY_DAY') \\\n",
    "                 .filter(F.col('COUNTRY')=='ES') \\\n",
    "                 .select(\n",
    "                        F.col('COUNTRY').alias('W_COUNTRY'),\n",
    "                        F.col('CITY_NAME'),\n",
    "                        F.col('DATE_VALID_STD'),\n",
    "                        F.col('AVG_TEMPERATURE_FEELSLIKE_2M_F')) \\\n",
    "                 .group_by(['W_COUNTRY', 'CITY_NAME', 'DATE_VALID_STD']) \\\n",
    "                 .agg(F.avg('AVG_TEMPERATURE_FEELSLIKE_2M_F').as_('AVG_TEMP_F'))\n",
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a UDF for converting from fahrenheit to celsius\n",
    "@udf(name=\"fahrenheit_to_celsius\", is_permanent=True, stage_location=\"@~\", replace=True)\n",
    "def fahrenheit_to_celsius(temp_f: float) -> float:\n",
    "    return (float(temp_f) - 32) * (5/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review Spanish daily sales per city\n",
    "pos_data = session.table('POS_FLATTENED_V') \\\n",
    "                  .select(\n",
    "                        F.col('ORDER_TS_DATE'),\n",
    "                        F.col('COUNTRY'),\n",
    "                        F.col('PRIMARY_CITY'),\n",
    "                        F.col('PRICE')) \\\n",
    "                  .where(F.col('COUNTRY') == 'Spain') \\\n",
    "                  .group_by('COUNTRY','PRIMARY_CITY','ORDER_TS_DATE') \\\n",
    "                  .agg(F.sum('PRICE').as_('TOTAL_SALES'))\n",
    "pos_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine POS and weather data for Spain\n",
    "pos_and_temp = pos_data.join(weather.select('W_COUNTRY', 'CITY_NAME', 'DATE_VALID_STD', 'AVG_TEMP_F') \\\n",
    "                                    .group_by(['W_COUNTRY', 'CITY_NAME', 'DATE_VALID_STD']) \\\n",
    "                                    .agg(F.sum('AVG_TEMP_F').as_('AVG_TEMP_F')), \n",
    "                                (pos_data['COUNTRY'] == 'Spain') & \n",
    "                                (weather['W_COUNTRY'] == 'ES') & \n",
    "                                (pos_data['PRIMARY_CITY'] == weather['CITY_NAME']) & \n",
    "                                (pos_data['ORDER_TS_DATE'] == weather['DATE_VALID_STD'])) \\\n",
    "                        .select(\n",
    "                                F.col('COUNTRY'),\n",
    "                                F.col('CITY_NAME'),\n",
    "                                F.col('DATE_VALID_STD').as_('DATE'),\n",
    "                                F.col('TOTAL_SALES'),\n",
    "                                F.round(F.col('AVG_TEMP_F'),1).alias('AVG_TEMP_F'),\n",
    "                                F.round(fahrenheit_to_celsius('AVG_TEMP_F'),1).alias('AVG_TEMP_C'))\n",
    "pos_and_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# materialize the results as a table\n",
    "pos_and_temp.write.save_as_table('DAILY_SALES_AND_TEMP_SPAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### next step, left to the reader: update the materialized table daily\n",
    "\n",
    "## hints:\n",
    "## create a stream on one of the views\n",
    "## create a stored procedure to update the materialized table\n",
    "## create a task to run the procedure daily"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
